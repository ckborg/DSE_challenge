{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Compare predicted values with DFT labeled data.\n",
    "1. Load in test data with DFT labels for stability.\n",
    "2. Compare against predicted values.\n",
    "3. Generate confusion matrix, F1 score and accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_dft = pd.read_csv('data/test_data_exploded_no_features_with_stability.csv')\n",
    "df_pred = pd.read_csv('data/test_data_exploded_magpie_featurized_predictions_rf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 218 6230 196\n",
      "F1 score:  0.319\n",
      "Accuracy:  0.939\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "for row_dft, row_pred in zip(df_dft.iterrows(), df_pred.iterrows()):\n",
    "    dft_val = row_dft[1]['is_stable']\n",
    "    pred_val = row_pred[1]['predicted_stabilityVec']\n",
    "    if '.' in row_dft[1]['unit_comp']:\n",
    "        if dft_val == True and pred_val == 1.0:\n",
    "            tp += 1\n",
    "        elif dft_val == False and pred_val == 1.0:\n",
    "            fp += 1\n",
    "        elif dft_val == True and pred_val == 0:\n",
    "            fn += 1\n",
    "        elif dft_val == False and pred_val == 0:\n",
    "            tn += 1\n",
    "print(tp, fp, tn, fn)\n",
    "\n",
    "# precision: What proportion of positive identifications was actually correct?\n",
    "precision = tp/(tp+fp)\n",
    "\n",
    "# recall: What proportion of actual positives was identified correctly?\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "accuracy = (tp+tn)/(tp+tn+fn+fp)\n",
    "\n",
    "# F1: more balanced accuracy metric\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "print('F1 score: ', round(F1, 3))\n",
    "print('Accuracy: ', round(accuracy, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
